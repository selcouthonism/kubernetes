# Kubernetes

Kubernetes (K8s) is a container orchestration platform designed to run containerized workloads reliably at scale. While Docker made containers easy to build and run, Kubernetes solves the harder problem: operating containers in production across multiple machines. It abstracts infrastructure into a cluster and provides declarative APIs so engineers describe desired state (e.g., “run 5 replicas of this service”) and Kubernetes continuously works to maintain that state.

At its core, Kubernetes manages scheduling, networking, and lifecycle of containers. It decides where containers should run based on resource availability, constraints, and policies; exposes applications through stable networking primitives; and restarts or reschedules workloads when failures occur. Concepts like Pods, Services, Deployments, and ReplicaSets allow teams to model complex systems while keeping deployments repeatable and automated.

From an operational standpoint, Kubernetes enables platform-level consistency across environments (dev, staging, prod) and across clouds or on-prem infrastructure. It integrates naturally with CI/CD, observability, security, and service mesh tooling. This makes Kubernetes less about running containers and more about building a reliable application platform for distributed systems and microservices.

## Docker vs Kubernetes Comparison
Docker is excellent for building and running containers; Kubernetes is essential for running containerized applications reliably at scale.

| Capability                   | Docker (Standalone / Docker Engine)                           | Kubernetes                                                                                       |
| ---------------------------- | ------------------------------------------------------------- | ------------------------------------------------------------------------------------------------ |
| **Container Scheduling**     | Manual or basic (single host, `docker run`, `docker-compose`) | Advanced, automatic scheduling across nodes based on CPU, memory, affinity, taints, and policies |
| **Load Balancing**           | Limited; requires external tools or manual setup              | Built-in via Services (ClusterIP, NodePort, LoadBalancer) with automatic traffic distribution    |
| **Application Scaling**      | Manual scaling (`docker-compose scale`)                       | Declarative, automatic scaling (ReplicaSets, HPA, VPA, autoscaling based on metrics)             |
| **Self-Healing**             | None by default (containers stay down if they crash)          | Built-in: restarts containers, reschedules Pods, replaces failed nodes                           |
| **Service Discovery**        | Manual networking and IP management                           | Native service discovery via DNS and Services                                                    |
| **Configuration Management** | Environment variables or mounted files (manual)               | ConfigMaps and Secrets, dynamically injected and versioned                                       |
| **Operational Scope**        | Single host or small setups                                   | Production-grade, multi-node, multi-cluster orchestration                                        |
| **Primary Role**             | Container runtime                                             | Container orchestration and application platform                                                 |
