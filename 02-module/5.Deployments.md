# Deployments
A Deployment is a higher-level Kubernetes workload resource that manages ReplicaSets and, indirectly, Pods, providing a declarative way to define how an application should be created, updated, scaled, and rolled back. Instead of managing Pods or ReplicaSets directly, you describe the desired state (number of replicas, container image, update strategy), and the Deployment controller ensures the cluster continuously converges to that state. This abstraction makes Deployments the standard choice for running stateless applications in production.

One of the most important features of a Deployment is **rolling updates**. When you change something like a container image version, Kubernetes creates a new ReplicaSet with the updated specification and gradually scales it up while scaling down the old ReplicaSet, according to the configured strategy (e.g., **RollingUpdate** with **maxSurge** and **maxUnavailable**). This allows zero-downtime deployments and controlled transitions between versions without manually deleting Pods.

Deployments also provide **versioning** and **rollback** capabilities. Every change to the Pod template creates a new revision, which Kubernetes keeps track of. If a deployment fails or introduces issues, you can easily roll back to a previous known-good version using a single command. Combined with built-in scaling (```kubectl scale deployment …```) and self-healing (recreating failed Pods), Deployments are the recommended mechanism for managing application lifecycles reliably and safely in Kubernetes.

## Deployment Strategies
In Kubernetes, deployment strategies define how Pods are updated when a Deployment changes (for example, when you update the container image). The strategy ensures availability, controls risk, and determines whether downtime is acceptable during the rollout.

### 1. RollingUpdate (Default Strategy)
RollingUpdate updates Pods gradually by creating new Pods with the updated version while terminating old Pods step by step. This strategy minimizes or eliminates downtime and is ideal for production workloads. It is controlled by two parameters:
- **maxUnavailable**: how many Pods can be unavailable during the update
- **maxSurge**: how many extra Pods can be temporarily created

Rolling updates allow continuous service availability and enable safe rollbacks if issues occur.

### 2. Recreate Strategy
With Recreate, Kubernetes first terminates all existing Pods and then creates new Pods with the updated version. This approach causes downtime but guarantees that no old and new versions run at the same time. It is useful when the application cannot support running multiple versions concurrently (for example, due to schema incompatibility).

### 3. Blue–Green Deployment (Pattern, not native)
In Blue–Green, two separate environments (blue = current, green = new) run side by side. Traffic is switched from blue to green once the new version is validated. Kubernetes does not provide this strategy natively, but it is implemented using multiple Deployments and Services. It enables near-instant rollbacks by switching traffic back to the old version.

### 4. Canary Deployment (Pattern)
A Canary deployment gradually exposes the new version to a small subset of users before rolling it out fully. This is typically implemented by running multiple Deployments with different replica counts or using traffic-splitting via a Service mesh (Istio, Linkerd) or Ingress controller. Canary deployments reduce risk by validating behavior in production with limited impact.

### 5. Shadow / Dark Launch (Advanced Pattern)
In this strategy, the new version receives a copy of production traffic but does not serve responses to users. It is mainly used for performance testing and validation under real load. This approach requires advanced routing and is often implemented with service meshes.

In real-world DevOps and production environments, RollingUpdate is most common, while Canary and Blue–Green are preferred for high-risk or mission-critical releases.

## Deployment Examples
```
kubectl get pods --watch
```
This command starts watching Pod resources in real time, continuously streaming updates to the terminal as Pods are created, updated, or deleted. It is commonly used before applying a Deployment so you can observe how Kubernetes creates new Pods, changes their status from **Pending** to **Running**, and manages restarts or replacements as part of the deployment process.

### Apply Deployment
```
kubectl apply -f nginx-deploy.yaml
```
This command creates (or updates) a Deployment defined in nginx-deploy.yaml using a declarative approach. Kubernetes reads the desired state from the manifest (such as replica count, container image, and update strategy) and the Deployment controller creates a ReplicaSet, which then creates the required number of Pods to match that desired state.

#### Get Information
```
kubectl get pods
```
This lists all Pods in the current namespace, allowing you to verify that the Pods created by the Deployment are running and to check their status, readiness, and restart counts. You’ll typically see multiple Pods with names derived from the Deployment and its underlying ReplicaSet.

```
kubectl get rs
```
This command displays the ReplicaSets in the namespace. For a Deployment, you’ll see at least one ReplicaSet created and managed automatically, which is responsible for maintaining the specified number of Pod replicas and handling Pod recreation if failures occur.

```
kubectl get deploy
kubectl get deployments
```
Both commands show the Deployments in the namespace (they are aliases). The output includes key rollout information such as desired, current, and available replicas, making it easy to assess whether the Deployment is healthy and fully rolled out.

```
kubectl describe deployment nginx-deployment
```
This provides a detailed, human-readable view of the Deployment, including its configuration, rollout strategy, associated ReplicaSets, and recent events. It’s especially useful for troubleshooting, as it shows why a rollout might be stuck or whether Pods are failing to become ready.

```
kubectl get deploy nginx-deployment -o yaml
```
This outputs the full YAML representation of the live Deployment object as stored in etcd, including system-generated fields like status, conditions, and revision history. It’s useful for auditing, debugging, or understanding how Kubernetes has normalized and applied your declarative configuration.

#### Delete Deployment
```
kubectl delete -f nginx-deploy.yaml
```
This deletes the Deployment defined in the manifest, which in turn deletes the managed ReplicaSets and all associated Pods. Kubernetes performs a clean teardown, ensuring that no application resources remain running once the Deployment is removed.

### Update the Depleyment image

#### Start watching Pods and ReplicaSets
```
kubectl get pods --watch
kubectl get rs --watch
```
These commands let you observe the rollout in real time. When the Deployment is updated, you will see new Pods being created and old ones being terminated, as well as a new ReplicaSet appearing. This live view makes it easy to understand how Kubernetes performs rolling updates without downtime.

#### Verify Changes Before Update
Update the image in nginx-deploy.yaml from nginx:latest to nginx:1.27.0-alpine and reapply the manifest.
```
kubectl diff -f nginx-deploy.yaml
```
This command shows the difference between the live Deployment running in the cluster and the desired state defined in nginx-deploy.yaml, without applying any changes. It works like a “preview” or dry-run for declarative updates, highlighting what fields (such as container image, replicas, or labels) will change if you run **kubectl apply**. This is especially useful before updating a Deployment, as it lets you verify the impact of the change, avoid accidental rollouts, and safely review configuration drift in production environments.

#### Update the image and reapply the Deployment manifest
```
kubectl apply -f nginx-deploy.yaml
```
After changing the container image from nginx:latest to nginx:1.27.0-alpine in the Deployment YAML, reapplying the manifest updates the desired state. The Deployment controller detects the image change and initiates a rolling update according to the Deployment strategy, instead of modifying existing Pods in place.

#### Observe the Deployment changes
```
kubectl describe deployment nginx-deployment
```
This command shows that a new ReplicaSet is created for the updated image version, while the old ReplicaSet is gradually scaled down. The Deployment manages this transition, ensuring the desired number of replicas remain available during the update and providing rollout history for easy rollback if needed.

### Rollout Deployment
```
kubectl rollout --help
```
This command displays all available rollout-related subcommands and options for managing Kubernetes workloads such as Deployments, StatefulSets, and DaemonSets. It is a reference point for understanding how to inspect rollout status, view revision history, pause or resume rollouts, and perform rollbacks in a controlled and auditable way.

```
kubectl rollout history deployment nginx-deployment
kubectl rollout history deployment/nginx-deployment
```
These commands list the rollout revision history of the specified Deployment, showing each revision number and any associated change causes. This history is generated whenever the Deployment’s Pod template changes and is essential for tracking what versions have been deployed and identifying safe rollback points.

```
kubectl rollout history deployment/nginx-deployment --revision=2 -o yaml
```
This command outputs the full YAML of a specific Deployment revision, allowing you to inspect the exact configuration (such as container image, environment variables, and labels) that was used in that rollout. It is useful for auditing changes and understanding precisely what will be restored during a rollback.

```
kubectl rollout undo deployment nginx-deployment
```
This command rolls the Deployment back to the previous revision by scaling down the current ReplicaSet and scaling up the earlier one. Kubernetes creates new Pods using the old ReplicaSet’s template (identified by its hash), enabling a fast and reliable rollback when a new version causes issues in production.

```
kubectl rollout status deployment nginx-deployment
```
This command monitors the progress of a Deployment rollout and reports whether it has successfully completed or is still in progress. It continuously checks that the new ReplicaSet’s Pods are created, become ready, and replace the old Pods according to the deployment strategy, blocking until the rollout finishes or fails. This is commonly used in CI/CD pipelines and operational workflows to ensure that a deployment update is healthy before proceeding to the next step.

```
kubectl annotate deployment/nginx-deployment 'kubernetes.io/change-cause'='Updated nginx image to version 1.27.0-alpine'
```
This command adds a human-readable annotation describing why a change was made, which is then displayed in rollout history. Annotating Deployments is a best practice in DevOps, as it improves traceability, makes rollbacks safer, and helps teams understand the context behind each revision.

```
kubectl describe deploy nginx-deployment
```
This command provides a detailed overview of the Deployment, including its rollout strategy, current and previous ReplicaSets, pod status, annotations (such as change causes), and recent events. It is commonly used to verify rollout progress, confirm successful updates or rollbacks, and troubleshoot deployment issues.

### Scale Deployment
```kubectl scale``` is fast and convenient, but it trades automation, auditability, and resilience for simplicity. In production-grade DevOps setups, it should be used sparingly and replaced with declarative or autoscaling mechanisms wherever possible.

#### Restart all Pods by scaling to zero and back up
```
kubectl scale deploy nginx-deployment --replicas=0
kubectl scale deploy nginx-deployment --replicas=5
```
Scaling a Deployment down to zero terminates all running Pods while keeping the Deployment, ReplicaSets, and configuration intact. Scaling it back up recreates Pods from the current ReplicaSet, which effectively restarts the entire application without changing the image or configuration. This is a common operational technique for recovering from transient issues or forcing Pods to pick up external changes like refreshed secrets or config maps.

#### Temporarily scale the Deployment to three Pods
```
kubectl scale deploy nginx-deployment --replicas=3
```
This command adjusts the desired replica count to three, prompting the Deployment controller to scale Pods up or down accordingly. It is typically used for load-based scaling, cost optimization, or maintenance windows, and Kubernetes ensures the change happens safely while maintaining availability based on the Deployment’s rollout strategy.

It has several drawbacks and limitations:

##### Manual and Non-Adaptive Scaling
This command performs static, manual scaling. It does not react to real-time load, traffic spikes, or resource usage. Once set, the replica count stays at 3 until someone changes it again, making it unsuitable for dynamic workloads compared to Horizontal Pod Autoscaler (HPA).

##### Configuration Drift Risk
If your Deployment is managed declaratively via GitOps or CI/CD pipelines, manually scaling with kubectl scale can cause drift between the cluster state and the source-of-truth manifests (e.g., Git). The next kubectl apply or pipeline run may overwrite this value.

##### No Rollout History or Audit Context
Scaling changes do not create a new Deployment revision or meaningful rollout history. There is no built-in explanation of why the replica count was changed, which reduces auditability unless annotations or external change tracking are used.

##### Ignores Resource Constraints
Scaling up or down does not consider cluster capacity automatically. Scaling up may fail if there are not enough CPU or memory resources, leaving Pods in Pending state and giving a false sense of availability.

##### Not Suitable for Self-Healing Policies
This command does not encode intent such as minimum availability or scaling rules. It simply sets a number. Best practices favor policies (HPA, VPA, autoscaling groups) over imperative commands.